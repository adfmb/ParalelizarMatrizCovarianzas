tofdg <- function(matriz){
a <- as.data.frame(matrix(0,nrow=dim(matriz)[1]**2/2,ncol=3))
contador <- 0
for(i in 1:dim(matriz)[2]){
col <- matriz[,i]
for(j in 1:i){
a[contador+1,3] <- as.numeric(matriz[i,j])
a[contador+1,2] <- j
a[contador+1,1] <- i
contador <- contador +1
}
}
a
}
x <- tofdg(adj.matrix)
z <- as.data.frame(cbind(seq(1,clusters,1),t(summary_cluster)))
colores2 <- as.data.frame(cbind(seq(1,clusters,1),t(colores)[1:clusters]))
qrage(links=x, width = 1000, height = 800,distance=8000,nodeValue=z
,nodeColor=colores2,linkColor='#00f',arrowColor='#f00'
,cut=0.01,textSize=12
,linkWidth=c(1,8),linkOpacity=c(0.6,1))
View(df_)
View(df)
browseURL("file:////Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html")
?fromJSON
library(jsonlite)
?fromJSON
mat <- matrix(c(1:3,7:9,4:6),byrow=T,nc=3)
which.max( mat[,2] )
mat[,2]
mat[,2]
which.max( mat[,2] )
which.min( mat[,2] )
library(fpc)
library(dbscan)
library(kernlab)
library(jsonlite)
library(igraph)
library(RColorBrewer)
library(qrage)
library(psych)
library(Rcpp)
library(maps)
library(mapproj)
library(ggplot2)
library(shiny)
library(R2jags)
library(rjags)
library(psych)
library(caret)
library(bnclassify)
library(klaR)
library(rocc)
#----------------------------- LOAD DATA -----------------------------
rm(list = ls())
#rutawork = ('/home/denny/itam/topologia/proyecto_clustering/')
rutawork = ('/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos/proyecto_clustering/')
datos <- read.csv(paste(rutawork,'ecobici_preprocessed.csv',sep = ""), header = TRUE, sep = ",", quote="\"", dec=".", fill = TRUE)
datos_origin<-datos
str(datos)
proporcion_entrena<-.01
inTraining <- createDataPartition(datos_origin$Genero_Usuario, p = proporcion_entrena, list = FALSE)
datos <- datos_origin[ inTraining,]
datos <- datos[c("Edad_Usuario", "Distancia_km", "Duracion_viaje")]
variables <- length(datos)
sigma <- 1
kres <- kpca(~., data=datos,features=variables,kernel="rbfdot",kpar = list(sigma = sigma))
data_kpca <- as.data.frame(kres@rotated)
#ordena de mayor a menor (por la que tiene mayor varianza)
datos_prueba <- data_kpca[c("V1","V2")]
#----------------------------- GENERATE INTERVALS----------------------------------
df <- datos_prueba      #choose a dataset
#----------------------------- NECESSARY PARAMETERS -----------------------------
#var_o <- data$x1    #variable we will use to make the overlapping subsets
var_o <- datos_prueba$V1   #if we want to use kernel pca variable to cut
n_int <- 6  #number of intervals we want
p <- 0.2  #proportion of each interval that should overlap with the next
#----------------------------- CREATING THE INTERVALS -----------------------------
#this section will create a data frame in which we will construct overlapping intervals
intervals_centers <- seq(min(var_o),max(var_o),length=n_int)  #basic partition = centers
interval_length <- intervals_centers[2]-intervals_centers[1]  #to create the overlaps of p% of this length
intervals <- data.frame(centers=intervals_centers)            #create a data frame
#create the overlapping intervals
intervals$min <- intervals_centers - (0.5+p)*interval_length
intervals$max <- intervals_centers + (0.5+p)*interval_length
intervals$interval <- seq(1,n_int)
intervals$name <- with(intervals, sprintf("[%.2f;%.2f)",min,max))
#function that will split the variable according to the invervals
res <- lapply(split(intervals,intervals$interval), function(x){
return(df[var_o> x$min & var_o <= x$max,])     #res will be a list with each element res[i]
})                                               #being the points on the i'th subset
df$Clusters<-numeric(nrow(df))
for(i in 1:length(res)){
# i<-1
interval_temp<-res[[i]]
distmat <- as.matrix(dist(interval_temp))
neigh <- 6
clusters_i<-clustITAM(distmat, neigh)
interval_temp$Cluster<-numeric(nrow(interval_temp))
for(j in 1:length(clusters_i)){
#j<-1
for(z in 1:length(clusters_i[[j]])){
#  z<-1
interval_temp$Cluster[as.numeric(clusters_i[[j]][z])]<-j
#df$Clusters[as.numeric(rownames(interval_temp)[nrow(interval_temp)])]<-j
}
}
res[[i]]<-interval_temp
}
for(i in 1:length(res)){
df[[ncol(df)+1]]<-numeric(nrow(df))
interval_temp<-res[[i]]
interval_temp$filas<-rownames(interval_temp)
for(j in 1:nrow(df)){
if(rownames(df)[j] %in% rownames(interval_temp)){
df[[ncol(df)]][j]<-interval_temp$Cluster[which(interval_temp$filas==rownames(df)[j])]
}#else{
#       df[[ncol(df)+1]][j]<-0
#     }
}
}
df_<-df
for(i in 1:length(res)){
ncol<-ncol(df_)
df_[[ncol+1]]<-numeric(nrow(df_))
ncol<-ncol(df_)
if(i==1){
contador_clusters<-0
df_[[ncol]]<-df_[[2+i]]
}else{
for(j in 1:nrow(df_)){
if(df_[[2+i]][j]!=0){
df_[[ncol]][j]<-df_[[2+i]][j]+contador_clusters
}
}
}
contador_clusters<-contador_clusters+max(df_[[2+i]])
}
df_salvado<-df
df<-df_[,-c(3:8)]
View(df_salvado)
View(df_)
library(fpc)
library(dbscan)
library(kernlab)
library(jsonlite)
library(igraph)
library(RColorBrewer)
library(qrage)
#----------------------------- LOAD DATA -----------------------------
rm(list = ls())
#rutawork = ('/home/denny/itam/topologia/proyecto_clustering/')
rutawork = ('/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos/proyecto_clustering/')
datos <- read.csv(paste(rutawork,'ecobici_preprocessed.csv',sep = ""), header = TRUE, sep = ",", quote="\"", dec=".", fill = TRUE)
datos_origin<-datos
datos<-datos_origin[c("Edad_Usuario", "Distancia_km", "Duracion_viaje")]
variables <- length(datos)
sigma <- 1
kres <- kpca(~., data=datos,features=variables,kernel="rbfdot",kpar = list(sigma = sigma))
print("WEEEEEEEEEY  YA QUEDÃ“ EL PINCHE PCA")
datos_prueba <- data_kpca[c("V1","V2")]
#----------------------------- GENERATE INTERVALS----------------------------------
df <- datos_prueba      #choose a dataset
#----------------------------- NECESSARY PARAMETERS -----------------------------
#var_o <- data$x1    #variable we will use to make the overlapping subsets
var_o <- datos_prueba$V1   #if we want to use kernel pca variable to cut
n_int <- 6  #number of intervals we want
p <- 0.2  #proportion of each interval that should overlap with the next
data_kpca <- as.data.frame(kres@rotated)
datos_prueba <- data_kpca[c("V1","V2")]
df <- datos_prueba      #choose a dataset
#----------------------------- NECESSARY PARAMETERS -----------------------------
#var_o <- data$x1    #variable we will use to make the overlapping subsets
var_o <- datos_prueba$V1   #if we want to use kernel pca variable to cut
n_int <- 6  #number of intervals we want
p <- 0.2  #proportion of each interval that should overlap with the next
#----------------------------- CREATING THE INTERVALS -----------------------------
#this section will create a data frame in which we will construct overlapping intervals
intervals_centers <- seq(min(var_o),max(var_o),length=n_int)  #basic partition = centers
interval_length <- intervals_centers[2]-intervals_centers[1]  #to create the overlaps of p% of this length
intervals <- data.frame(centers=intervals_centers)            #create a data frame
#create the overlapping intervals
intervals$min <- intervals_centers - (0.5+p)*interval_length
intervals$max <- intervals_centers + (0.5+p)*interval_length
intervals$interval <- seq(1,n_int)
intervals$name <- with(intervals, sprintf("[%.2f;%.2f)",min,max))
#function that will split the variable according to the invervals
res <- lapply(split(intervals,intervals$interval), function(x){
return(df[var_o> x$min & var_o <= x$max,])     #res will be a list with each element res[i]
})                                               #being the points on the i'th subset
df$Clusters<-numeric(nrow(df))
for(i in 1:length(res)){
# i<-1
interval_temp<-res[[i]]
distmat <- as.matrix(dist(interval_temp))
neigh <- 6
clusters_i<-clustITAM(distmat, neigh)
interval_temp$Cluster<-numeric(nrow(interval_temp))
for(j in 1:length(clusters_i)){
#j<-1
for(z in 1:length(clusters_i[[j]])){
#  z<-1
interval_temp$Cluster[as.numeric(clusters_i[[j]][z])]<-j
#df$Clusters[as.numeric(rownames(interval_temp)[nrow(interval_temp)])]<-j
}
}
res[[i]]<-interval_temp
}
// [[Rcpp::export]]
LogicalVector bfs_density_component(NumericMatrix distmat, int root=0, double jump_factor=3, int nbs=10) {
int n = distmat.nrow(); // cantidad de datos
LogicalVector visited(n); // indicara si un nodo esta conectado o no
double infinity=999999999;
double density, sum_local_dists; // empezamos con un valor muy grande para la primera iter
queue<int> aux_queue; // la cola que vamos a usar
int i; // iterador principal
// STEP 0: BEFORE START
for(i=0; i<n; i++){
visited[i] = false;
}
// STEP 1: INITIAL VALUES FOR BREADTH SEARCH
NumericVector distances = distmat.row(root);
NumericVector neighbours(nbs);
distances[root] = infinity;
visited[root] = true;
int n_visited = 0; // para actualizar la densidad
int nbs_queued;
int top=root; // el frente de la cola
aux_queue.push(root);
density = infinity;
// STEP 2: BREADTH-SEARCH
do{
// tomamos el frente de la cola
// cout << "Padre: " << aux_queue.front();
top = aux_queue.front();
aux_queue.pop(); // quitamos el elemento tope
// queremos calcular la distancias para la densidad y los vecinos
distances = distmat.row(top);
distances[top] = infinity;
// vamos a ver que vecinos vamos a visitar
neighbours = smallest_k(distances, nbs);
nbs_queued=0;
sum_local_dists=0;
for(i=0; i < nbs; i++){
// cout << "; vecino " << neighbours[i] << ": " << distances[neighbours[i]] << ", ";
if(!visited[neighbours[i]] && (distances[neighbours[i]] < jump_factor*density) ){
aux_queue.push(neighbours[i]);
visited[neighbours[i]] = true;
sum_local_dists += distances[neighbours[i]];
nbs_queued++;
}
}
density = (density*n_visited + sum_local_dists)/(n_visited + nbs_queued);
n_visited += nbs_queued;
// cout << "densidad: " << density;
// cout << endl;
} while (!aux_queue.empty());
return visited;
}
Rcpp::sourceCpp('Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/git_Denny/TDA_proyectos/proyecto_clustering/graphTheory.cpp')
clustITAM <- function(distmat, neigh){
mat <- distmat
dimnames(mat)=list(1:nrow(distmat),1:nrow(distmat))
clustList <- list()
while(nrow(mat)!=0){
indices <- which(bfs_density_component(mat, nbs=neigh))
if((nrow(mat)-length(indices))!=1){
individuos <- row.names(mat)[indices]
mat <- mat[-indices, -indices]
clustList <- c(clustList, list(individuos))
} else{
el_we_solito <- row.names(mat)[!(row.names(mat) %in% row.names(mat)[indices])]
individuos <- row.names(mat)[indices]
clustList <- c(clustList, list(individuos), list(el_we_solito))
break
}
}
return(clustList)
}
intervals_centers <- seq(min(var_o),max(var_o),length=n_int)  #basic partition = centers
interval_length <- intervals_centers[2]-intervals_centers[1]  #to create the overlaps of p% of this length
intervals <- data.frame(centers=intervals_centers)            #create a data frame
#create the overlapping intervals
intervals$min <- intervals_centers - (0.5+p)*interval_length
intervals$max <- intervals_centers + (0.5+p)*interval_length
intervals$interval <- seq(1,n_int)
intervals$name <- with(intervals, sprintf("[%.2f;%.2f)",min,max))
res <- lapply(split(intervals,intervals$interval), function(x){
return(df[var_o> x$min & var_o <= x$max,])     #res will be a list with each element res[i]
})                                               #being the points on the i'th subset
df$Clusters<-numeric(nrow(df))
for(i in 1:length(res)){
# i<-1
interval_temp<-res[[i]]
distmat <- as.matrix(dist(interval_temp))
neigh <- 6
clusters_i<-clustITAM(distmat, neigh)
interval_temp$Cluster<-numeric(nrow(interval_temp))
for(j in 1:length(clusters_i)){
#j<-1
for(z in 1:length(clusters_i[[j]])){
#  z<-1
interval_temp$Cluster[as.numeric(clusters_i[[j]][z])]<-j
#df$Clusters[as.numeric(rownames(interval_temp)[nrow(interval_temp)])]<-j
}
}
res[[i]]<-interval_temp
}
for(i in 1:length(res)){
df[[ncol(df)+1]]<-numeric(nrow(df))
interval_temp<-res[[i]]
interval_temp$filas<-rownames(interval_temp)
for(j in 1:nrow(df)){
if(rownames(df)[j] %in% rownames(interval_temp)){
df[[ncol(df)]][j]<-interval_temp$Cluster[which(interval_temp$filas==rownames(df)[j])]
}#else{
#       df[[ncol(df)+1]][j]<-0
#     }
}
}
df_<-df
View(df)
for(i in 1:length(res)){
ncol<-ncol(df_)
df_[[ncol+1]]<-numeric(nrow(df_))
ncol<-ncol(df_)
if(i==1){
contador_clusters<-0
df_[[ncol]]<-df_[[2+i]]
}else{
for(j in 1:nrow(df_)){
if(df_[[2+i]][j]!=0){
df_[[ncol]][j]<-df_[[2+i]][j]+contador_clusters
}
}
}
contador_clusters<-contador_clusters+max(df_[[2+i]])
}
View(df_)
df_salvado<-df
df<-df_[,-c(3:8)]
View(df)
View(df_salvado)
df_<-df_salvado
length(res)
View(df_)
for(i in 1:length(res)){
ncol<-ncol(df_)
df_[[ncol+1]]<-numeric(nrow(df_))
ncol<-ncol(df_)
if(i==1){
contador_clusters<-0
df_[[ncol]]<-df_[[2+i]]
}else{
for(j in 1:nrow(df_)){
if(df_[[2+i]][j]!=0){
df_[[ncol]][j]<-df_[[2+i]][j]+contador_clusters
}
}
}
contador_clusters<-contador_clusters+max(df_[[2+i]])
}
View(df_)
df_<-df_salvado
for(i in 1:length(res)){
ncol<-ncol(df_)
df_[[ncol+1]]<-numeric(nrow(df_))
ncol<-ncol(df_)
if(i==1){
contador_clusters<-0
df_[[ncol]]<-df_[[3+i]]
}else{
for(j in 1:nrow(df_)){
if(df_[[3+i]][j]!=0){
df_[[ncol]][j]<-df_[[3+i]][j]+contador_clusters
}
}
}
contador_clusters<-contador_clusters+max(df_[[3+i]])
}
df_salvado<-df
df<-df_[,-c(3:8)]
base <- df
base$clusters<-0
int_fin <- ncol(base)-1
#Columna en donde empieza el intervalo 1:
int_ini <- int_fin-n_int+1
#Columna donde se creo la columna de "clusters":
col_cluster <- ncol(base)
View(df)
View(df_)
for(i in seq(nrow(base[,int_ini:int_fin]))){
temp<-c()
for(m in seq(int_ini,int_fin)){
if (base[i,m] > 0){
temp<-c(paste0(temp,base[i,m],sep = ","))
}
}
if(length((temp))>0){
aux<-unlist(strsplit(temp,","))
aux2<-unique(aux)
aux3<-paste(aux2,collapse=",")
base[i,col_cluster]<-aux3
}
}
base <- data.frame(base$clusters)
names(base) <- c("clusters")
base$obs <- paste("obs",seq(1,length(base$clusters)))
num_clusters <- sort(as.numeric(unique(strsplit(paste0(base$clusters, collapse=","),",")[[1]])))
a<-strsplit(paste0(base$clusters, collapse=","),",")
clusters <- length((num_clusters))
for(x in num_clusters){
base[[paste("c",x,sep="_")]] <- rep(0,nrow(base))
}
base$clusters<- as.character(base$clusters)
for(i in seq(nrow(base))){
vector <- strsplit(base$clusters[i], ",")[[1]]
vector <- sort(as.numeric(vector))
for(x in vector){
base[i,(x+int_ini)] <- 1
}
}
if(sum(base[[3]])==0){
dummy_mat<-base[,4:ncol(base)]
}else{dummy_mat<-base[,3:ncol(base)]}
n_clusters<-ncol(dummy_mat)
cluster_list<-lapply(1:n_clusters,function (col) {which(dummy_mat[,col]==1)})
adj_matrix<-matrix(0,nrow=n_clusters,ncol=n_clusters)
for(i in 1:(n_clusters-1)){
# i<-1
for(j in (i+1):n_clusters){
# j<-i+1
distancia<-setdiff(cluster_list[[i]], cluster_list[[j]])
cercania<-length(cluster_list[[i]])-length(distancia)
adj_matrix[i,j]<-round(cercania/min(length(cluster_list[[i]]),length(cluster_list[[j]])),2)
adj_matrix[j,i]<-adj_matrix[i,j]
}
}
summary_cluster<-matrix(0,nrow=1,ncol=n_clusters)
for(i in 1:n_clusters){
summary_cluster[1,i]<-length(cluster_list[[i]])
}
nodes.n <- clusters
nodes.size<- as.numeric(summary_cluster)/100
nodes.tooltips <- paste("Grupo:", 1:nodes.n)
nodes.names <- 1:nodes.n
nodes.color <- as.character(1:nodes.n)
adj.matrix <- adj_matrix
aux_mat <- data.frame()
for(i in 1:nodes.n) {
for(j in 1:nodes.n){
if(adj.matrix[i, j]!=0) {
aux_mat <- rbind(aux_mat, data.frame(source=i-1, target=j-1, value=adj.matrix[i, j]))
}
}
}
adj.matrix[i, j]
linksJSON <- toJSON(aux_mat)
nodesJSON <- toJSON(data.frame(color=nodes.color, group=nodes.size, name=nodes.names, tooltip=nodes.tooltips))
graphJSON <- sprintf("{\"nodes\": %s, \"links\": %s}", nodesJSON, linksJSON)
htmlFile <- readLines('/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html')
graph_def_line <- which(grepl("graph =", htmlFile))
#htmlFile[graph_def_line] <- sprintf("graph = %s;", graphJSON)
htmlFile[graph_def_line] <- sprintf("graph = %s;", graphJSON)
#writeLines(htmlFile, "www/index.html")
#writeLines(htmlFile, '/home/denny/itam/topologia/ManifoldLearning/www/index.html')
writeLines(htmlFile,'/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html')
browseURL("file:////Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html")
graphJSON <- sprintf("{\"nodes\": %s, \"links\": %s}", nodesJSON, linksJSON)
nodesJSON <- toJSON(data.frame(color=nodes.color, group=nodes.size, name=nodes.names, tooltip=nodes.tooltips))
linksJSON <- toJSON(aux_mat)
nodesJSON <- toJSON(data.frame(color=nodes.color, group=nodes.size, name=nodes.names, tooltip=nodes.tooltips))
length(nodesJSON)
nodesJSON <- toJSON(data.frame(color=nodes.color, group=nodes.size, name=nodes.names, tooltip=nodes.tooltips))
View(summary_cluster)
summary_cluster[,-1]
nodes.size<- as.numeric(summary_cluster[,-1])/100
nodesJSON <- toJSON(data.frame(color=nodes.color, group=nodes.size, name=nodes.names, tooltip=nodes.tooltips))
graphJSON <- sprintf("{\"nodes\": %s, \"links\": %s}", nodesJSON, linksJSON)
htmlFile <- readLines('/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html')
#htmlFile <- readLines("www/index.html")
graph_def_line <- which(grepl("graph =", htmlFile))
#htmlFile[graph_def_line] <- sprintf("graph = %s;", graphJSON)
htmlFile[graph_def_line] <- sprintf("graph = %s;", graphJSON)
#writeLines(htmlFile, "www/index.html")
#writeLines(htmlFile, '/home/denny/itam/topologia/ManifoldLearning/www/index.html')
writeLines(htmlFile,'/Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html')
browseURL("file:////Users/jalfredomb/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/Topologia/TDA_proyectos//ManifoldLearning/www/index.html")
setwd("~/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/ComputoParalelo/Comp_Paralelo/ParalelizarMatrizCovarianzas")
generar_matriz(50,10,-2,100)
generar_matriz<-function(filas,columnas,minimo=-1,maximo=50){
#   filas<-3
#   columnas<-5
#   minimo=-1
#   maximo<-50
m<-matrix(cbind(round(runif(filas*columnas,minimo,maximo))),ncol=columnas)
setwd("~/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/ComputoParalelo/Comp_Paralelo/ParalelizarMatrizCovarianzas")
out <- file("fuente.csv", "w", encoding="latin1")
write.table(m, out, sep=",", row.names=FALSE,col.names = FALSE)
close(out)
}
setwd("~/Dropbox/01_ITAM_Ciencia_de_Datos/2do_semestre/ComputoParalelo/Comp_Paralelo/ParalelizarMatrizCovarianzas")
generar_matriz(50,10,-2,100)
Matriz<-read.csv("fuente.csv",header = FALSE)
M_covarianzas<-cov(Matriz)*(nrow(Matriz)-1)/nrow(Matriz)
M_covarianzas[ncol(M_covarianzas),ncol(M_covarianzas)]
View(M_covarianzas)
View(Matriz)
generar_matriz(50,500,-2,100)
Matriz<-read.csv("fuente.csv",header = FALSE)
M_covarianzas<-cov(Matriz)*(nrow(Matriz)-1)/nrow(Matriz)
M_covarianzas[ncol(M_covarianzas),ncol(M_covarianzas)]
